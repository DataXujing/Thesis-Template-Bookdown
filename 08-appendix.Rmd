# 附录 {#appendix .unnumbered}

\chaptermark{附录}

## 软件信息  {#sessioninfo .unnumbered}

```{r,echo=TRUE}
xfun::session_info(packages = c("rmarkdown", "bookdown"), dependencies = FALSE)
```


## 随机数生成 {#random-number-generation .unnumbered}

基于空间广义线性混合效应模型生成随机数的函数：
`generate_sim_data` 函数可生成响应变量服从泊松分布或二项分布，平稳高斯过程的自相关函数为二次幂指数族或梅隆族的随机数

```{r,eval=FALSE,echo=TRUE}
generate_sim_data <- function(N = 49, intercept = -1.0, 
                              slope1 = 1.0, slope2 = 0.5,
                              lscale = 1, sdgp = 1, 
                              cov.model = "exp_quad", type = "binomal") {
  # set.seed(2018) 
  ## 单位区域上采样
  d <- expand.grid(
    d1 = seq(0, 1, l = sqrt(N)),
    d2 = seq(0, 1, l = sqrt(N))
  )
  D <- as.matrix(dist(d)) # 计算采样点之间的欧氏距离
  switch (cov.model,
          matern = {
            phi = lscale
            corr_m = geoR::matern(D, phi = phi, kappa = 2) # 固定的 kappa = 2 
            m  = sdgp^2 * corr_m 
          },
          exp_quad = {
            phi <- 2 * lscale^2
            m <- sdgp^2 * exp(-D^2 / phi) # 多元高斯分布的协方差矩阵
          }
  )
  # powered.exponential (or stable)
  # rho(h) = exp[-(h/phi)^kappa] if 0 < kappa <= 2 此处 kappa 固定为 2
  S <- MASS::mvrnorm(1, rep(0, N), m) # 产生服从多元高斯分布的随机数
  # 模拟两个固定效应
  x1 <- rnorm(N, 0, 1)
  x2 <- rnorm(N, 0, 4)
  switch(type,
         binomal = {
           units.m <- rep(100, N) # N 个 100
           pred <- intercept + slope1 * x1 + slope2 * x2 + S
           mu <- exp(pred) / (1 + exp(pred))
           y <- rbinom(N, size = 100, prob = mu) # 每个采样点抽取100个样本
           data.frame(d, y, units.m, x1, x2)
         },
         poisson = {
           pred <- intercept + slope1 * x1 + slope2 * x2 + S
           y <- rpois(100, lambda = exp(pred)) # lambda 是泊松分布的期望  
           # Y ~ Possion(lambda) g(u) = ln(u) u = lambda = exp(g(u))
           data.frame(d, y, x1, x2)
         }
  )
}
```

## 算法比较 {#compare-algrithms .unnumbered}

```{r,echo=TRUE,eval=FALSE}
# 加载程序包
library(rstan)
library(brms)
# 以并行方式运行STAN-MCMC算法，指定CPU的核心数
options(mc.cores = parallel::detectCores())
# 将编译后的模型写入磁盘，可防止重新编译
rstan_options(auto_write = TRUE)
theme_set(theme_default())
prior <- c(
  set_prior("normal(0,10)", class = "b"), # 均值0 标准差 10 的先验
  set_prior("lognormal(0,1)", class = "lscale"),
  set_prior("lognormal(0,1)", class = "sdgp")
)
sim_binom_data <- generate_sim_data(type = "binomal")
benchmark.binomal <- microbenchmark::microbenchmark({
  fit.binomal <- brm(y | trials(units.m) ~ 0 + intercept + x1 + x2 + gp(d1, d2),
    sim_binom_data,
    prior = prior,
    chains = 4, thin = 5, iter = 15000, warmup = 5000,
    algorithm = "sampling", family = binomial()
  )
}, times = 10L)
summary(fit.binomal)

sim_poisson_data <- generate_sim_data(type = "poisson")
benchmark.poisson <- microbenchmark::microbenchmark({
  fit.poisson <- brm(y ~ 0 + intercept + x1 + x2 + gp(d1, d2),
    sim_poisson_data,
    prior = prior,
    chains = 4, thin = 5, iter = 15000, warmup = 5000, 
    algorithm = "sampling", family = poisson()
  )
}, times = 10L)
summary(fit.poisson)
plot(fit.poisson)
```

STAN 代码模拟高斯过程，自协方差函数见方程 \ref{eq:exp-quad}

```{r,echo=FALSE,comment=NA}
cat(readLines("code/gp.stan"),sep = "\n")
```

```{r,eval=is_on_travis,echo=is_on_travis,message=FALSE,warning=FALSE}
cat(system("cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c", intern = TRUE), sep = "\n")
parallel::detectCores()
# 32  Intel(R) Xeon(R) CPU E5-2680 v2 @ 2.80GHz
# options(mc.cores = ceiling(parallel::detectCores()/2))
library(rstan)
options(mc.cores = 4)
rstan_options(auto_write = TRUE)

schools_dat <- list(
  J = 8,
  y = c(28, 8, -3, 7, -1, 1, 18, 12),
  sigma = c(15, 10, 16, 11, 9, 11, 10, 18)
)
fit <- stan(
    model_name = "8schools",
    model_code = "
      // saved as 8schools.stan
      data {
        int<lower=0> J; // number of schools 
        real y[J]; // estimated treatment effects
        real<lower=0> sigma[J]; // s.e. of effect estimates 
      }
      parameters {
        real mu; 
        real<lower=0> tau;
        real eta[J];
      }
      transformed parameters {
        real theta[J];
        for (j in 1:J)
          theta[j] = mu + tau * eta[j];
      }
      model {
        target += normal_lpdf(eta | 0, 1);
        target += normal_lpdf(y | theta, sigma);
      }",
    data = schools_dat,
    iter = 10000, chains = 4,
    seed = 2018
  )
gc()
print(fit, digits = 3)
plot(fit)
devtools::session_info()
```

