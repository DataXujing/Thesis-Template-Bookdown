<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Master Thesis Template</title>
  <meta name="description" content="Spatial generalized linear mixed models, Stationary Spatial Gaussian Process, Stan platform, Markov chain Monte Carlo.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Master Thesis Template" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/logo.png" />
  <meta property="og:description" content="Spatial generalized linear mixed models, Stationary Spatial Gaussian Process, Stan platform, Markov chain Monte Carlo." />
  <meta name="github-repo" content="XiangyunHuang/Thesis-Template-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Master Thesis Template" />
  
  <meta name="twitter:description" content="Spatial generalized linear mixed models, Stationary Spatial Gaussian Process, Stan platform, Markov chain Monte Carlo." />
  <meta name="twitter:image" content="images/logo.png" />

<meta name="author" content="Xiang-Yun Huang">


<meta name="date" content="2018-10-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
<link rel="prev" href="index.html">
<link rel="next" href="models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">空间广义线性混合效应模型及其应用</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 绪论</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#motivations"><i class="fa fa-check"></i><b>1.1</b> 研究意义</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#reviews"><i class="fa fa-check"></i><b>1.2</b> 文献综述</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#stracture"><i class="fa fa-check"></i><b>1.3</b> 论文结构</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#Conventions-Colophon"><i class="fa fa-check"></i><b>1.4</b> 符号说明</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="prepare.html"><a href="prepare.html"><i class="fa fa-check"></i><b>2</b> 基础知识</a><ul>
<li class="chapter" data-level="2.1" data-path="prepare.html"><a href="prepare.html#sec:exp"><i class="fa fa-check"></i><b>2.1</b> 指数族</a></li>
<li class="chapter" data-level="2.2" data-path="prepare.html"><a href="prepare.html#lse"><i class="fa fa-check"></i><b>2.2</b> 最小二乘估计</a></li>
<li class="chapter" data-level="2.3" data-path="prepare.html"><a href="prepare.html#def-mle"><i class="fa fa-check"></i><b>2.3</b> 极大似然估计</a></li>
<li class="chapter" data-level="2.4" data-path="prepare.html"><a href="prepare.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> 随机过程的连续性和可微性</a></li>
<li class="chapter" data-level="2.5" data-path="prepare.html"><a href="prepare.html#stationary-gaussian-process"><i class="fa fa-check"></i><b>2.5</b> 平稳高斯过程</a></li>
<li class="chapter" data-level="2.6" data-path="prepare.html"><a href="prepare.html#Modified-Bessel-functions"><i class="fa fa-check"></i><b>2.6</b> 修正的第三类贝塞尔函数</a></li>
<li class="chapter" data-level="2.7" data-path="prepare.html"><a href="prepare.html#Laplace-approximation"><i class="fa fa-check"></i><b>2.7</b> 拉普拉斯近似</a></li>
<li class="chapter" data-level="2.8" data-path="prepare.html"><a href="prepare.html#Jeffreys-prior"><i class="fa fa-check"></i><b>2.8</b> Jeffreys 先验分布</a></li>
<li class="chapter" data-level="2.9" data-path="prepare.html"><a href="prepare.html#bayes-methods"><i class="fa fa-check"></i><b>2.9</b> 贝叶斯定理与先验分布</a></li>
<li class="chapter" data-level="2.10" data-path="prepare.html"><a href="prepare.html#Curse-of-Dimensionality"><i class="fa fa-check"></i><b>2.10</b> 维数灾难与蒙特卡罗积分</a></li>
<li class="chapter" data-level="2.11" data-path="prepare.html"><a href="prepare.html#Samplers"><i class="fa fa-check"></i><b>2.11</b> 采样器与 Stan</a></li>
<li class="chapter" data-level="2.12" data-path="prepare.html"><a href="prepare.html#section-2.12"><i class="fa fa-check"></i><b>2.12</b> 方差缩减因子</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>3</b> 统计模型</a><ul>
<li class="chapter" data-level="3.1" data-path="models.html"><a href="models.html#Linear-Models"><i class="fa fa-check"></i><b>3.1</b> 线性模型</a></li>
<li class="chapter" data-level="3.2" data-path="models.html"><a href="models.html#Generalized-Linear-Models"><i class="fa fa-check"></i><b>3.2</b> 广义线性模型</a></li>
<li class="chapter" data-level="3.3" data-path="models.html"><a href="models.html#Generalized-Linear-Mixed-Effects-Models"><i class="fa fa-check"></i><b>3.3</b> 广义线性混合效应模型</a></li>
<li class="chapter" data-level="3.4" data-path="models.html"><a href="models.html#Spatial-Generalized-linear-mixed-effects-models"><i class="fa fa-check"></i><b>3.4</b> 空间广义线性混合效应模型</a><ul>
<li class="chapter" data-level="3.4.1" data-path="models.html"><a href="models.html#intro-sglmm"><i class="fa fa-check"></i><b>3.4.1</b> 模型结构</a></li>
<li class="chapter" data-level="3.4.2" data-path="models.html"><a href="models.html#covariance-function"><i class="fa fa-check"></i><b>3.4.2</b> 协方差函数</a></li>
<li class="chapter" data-level="3.4.3" data-path="models.html"><a href="models.html#identify"><i class="fa fa-check"></i><b>3.4.3</b> 模型识别</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="algorithms.html"><a href="algorithms.html"><i class="fa fa-check"></i><b>4</b> 参数估计</a><ul>
<li class="chapter" data-level="4.1" data-path="algorithms.html"><a href="algorithms.html#mle"><i class="fa fa-check"></i><b>4.1</b> 极大似然估计</a></li>
<li class="chapter" data-level="4.2" data-path="algorithms.html"><a href="algorithms.html#profile-likelihood"><i class="fa fa-check"></i><b>4.2</b> 剖面似然估计</a></li>
<li class="chapter" data-level="4.3" data-path="algorithms.html"><a href="algorithms.html#algrithms"><i class="fa fa-check"></i><b>4.3</b> 参数估计的算法</a><ul>
<li class="chapter" data-level="4.3.1" data-path="algorithms.html"><a href="algorithms.html#LA"><i class="fa fa-check"></i><b>4.3.1</b> 拉普拉斯近似算法</a></li>
<li class="chapter" data-level="4.3.2" data-path="algorithms.html"><a href="algorithms.html#MCML"><i class="fa fa-check"></i><b>4.3.2</b> 蒙特卡罗极大似然算法</a></li>
<li class="chapter" data-level="4.3.3" data-path="algorithms.html"><a href="algorithms.html#MCMC"><i class="fa fa-check"></i><b>4.3.3</b> 贝叶斯 MCMC 算法</a></li>
<li class="chapter" data-level="4.3.4" data-path="algorithms.html"><a href="algorithms.html#LowRank"><i class="fa fa-check"></i><b>4.3.4</b> 低秩近似算法</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="algorithms.html"><a href="algorithms.html#STAN-MCMC"><i class="fa fa-check"></i><b>4.4</b> 贝叶斯 STAN-MCMC 算法</a><ul>
<li class="chapter" data-level="4.4.1" data-path="algorithms.html"><a href="algorithms.html#section-4.4.1"><i class="fa fa-check"></i><b>4.4.1</b> 算法提出的背景和意义</a></li>
<li class="chapter" data-level="4.4.2" data-path="algorithms.html"><a href="algorithms.html#STANMCMC"><i class="fa fa-check"></i><b>4.4.2</b> STAN-MCMC 算法实现过程</a></li>
<li class="chapter" data-level="4.4.3" data-path="algorithms.html"><a href="algorithms.html#-r-"><i class="fa fa-check"></i><b>4.4.3</b> 求解模型的 R 包</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simulations.html"><a href="simulations.html"><i class="fa fa-check"></i><b>5</b> 数值模拟</a><ul>
<li class="chapter" data-level="5.1" data-path="simulations.html"><a href="simulations.html#spatial-gaussian-processes"><i class="fa fa-check"></i><b>5.1</b> 平稳空间高斯过程</a><ul>
<li class="chapter" data-level="5.1.1" data-path="simulations.html"><a href="simulations.html#sim-one-gp"><i class="fa fa-check"></i><b>5.1.1</b> 一维平稳空间高斯过程</a></li>
<li class="chapter" data-level="5.1.2" data-path="simulations.html"><a href="simulations.html#sim-two-gp"><i class="fa fa-check"></i><b>5.1.2</b> 二维平稳空间高斯过程</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simulations.html"><a href="simulations.html#sim-sglmm"><i class="fa fa-check"></i><b>5.2</b> 空间广义线性混合效应模型</a><ul>
<li class="chapter" data-level="5.2.1" data-path="simulations.html"><a href="simulations.html#sim-binomal-sglmm"><i class="fa fa-check"></i><b>5.2.1</b> 响应变量服从二项分布</a></li>
<li class="chapter" data-level="5.2.2" data-path="simulations.html"><a href="simulations.html#possion-sglmm"><i class="fa fa-check"></i><b>5.2.2</b> 响应变量服从泊松分布</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>6</b> 数据分析</a><ul>
<li class="chapter" data-level="6.1" data-path="applications.html"><a href="applications.html#sptial-random-effects"><i class="fa fa-check"></i><b>6.1</b> 空间线性混合效应模型</a></li>
<li class="chapter" data-level="6.2" data-path="applications.html"><a href="applications.html#case-loaloa"><i class="fa fa-check"></i><b>6.2</b> 喀麦隆及周边地区盘尾丝虫病的空间分布</a></li>
<li class="chapter" data-level="6.3" data-path="applications.html"><a href="applications.html#case-rongelap"><i class="fa fa-check"></i><b>6.3</b> 朗格拉普岛核污染浓度的空间分布</a></li>
<li class="chapter" data-level="6.4" data-path="applications.html"><a href="applications.html#case-gambia"><i class="fa fa-check"></i><b>6.4</b> 冈比亚儿童疟疾流行强度的空间分布</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>7</b> 总结展望</a></li>
<li class="chapter" data-level="" data-path="ack.html"><a href="ack.html"><i class="fa fa-check"></i>致谢</a></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>作者简介</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>附录</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#tables-simulations"><i class="fa fa-check"></i>表格</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#simulate-code"><i class="fa fa-check"></i>代码</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#simulate-SGP-code"><i class="fa fa-check"></i>模拟平稳空间高斯过程</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#simulate-SGLMM-code"><i class="fa fa-check"></i>模拟空间广义线性模型</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#HMC-Algrithms"><i class="fa fa-check"></i>HMC 算法</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#compileinfo"><i class="fa fa-check"></i>编译信息</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#hardwareinfo"><i class="fa fa-check"></i>硬件环境</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#sysinfo"><i class="fa fa-check"></i>系统环境</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#softwareinfo"><i class="fa fa-check"></i>软件环境</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">本论文由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Master Thesis Template</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prepare" class="section level1">
<h1><span class="header-section-number">第 2 章</span> 基础知识</h1>
<p><span class="todo">本章概要</span></p>
<div id="sec:exp" class="section level2">
<h2><span class="header-section-number">2.1</span> 指数族</h2>
<p>一般地，样本 <span class="math inline">\(\mathbf{Y}\)</span> 的分布服从指数族，即形如</p>
<p><span class="math display" id="eq:common-exponential-family">\[\begin{equation}
f_{Y}(y;\theta,\phi) = \exp\big\{ \big(y\theta - b(\theta) \big)/a(\phi) + c(y,\phi) \big\}
\tag{2.1}
\end{equation}\]</span></p>
<p>其中，<span class="math inline">\(a(\cdot),b(\cdot),c(\cdot)\)</span> 是某些特定的函数。如果 <span class="math inline">\(\phi\)</span> 已知，这是一个含有典则参数 <span class="math inline">\(\theta\)</span> 的指数族模型，如果 <span class="math inline">\(\phi\)</span> 未知，它可能是含有两个参数的指数族。对于正态分布</p>
<p><span class="math display" id="eq:normal-distribution">\[\begin{equation}
\begin{aligned}
f_{Y}(y;\theta,\phi) &amp; = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\{-\frac{(y - \mu)^2}{2\sigma^2}  \}  \\
 &amp; = \exp\big \{ (y\mu - \mu^2/2)/\sigma^2 - \frac{1}{2}\big(y^2/\sigma^2 + \log(2\pi\sigma^2)\big) \big\}
\end{aligned} \tag{2.2}
\end{equation}\]</span></p>
<p>通过与 <a href="prepare.html#eq:common-exponential-family">(2.1)</a> 式对比，可知 <span class="math inline">\(\theta = \mu\)</span>，<span class="math inline">\(\phi = \sigma^2\)</span>，并且有</p>
<p><span class="math display">\[
a(\phi) = \phi, \quad b(\theta) = \theta^2/2, \quad c(y,\phi) = - \frac{1}{2}\{ y^2/\sigma^2 + \log(2\pi\sigma^2) \} 
\]</span></p>
<p>记 <span class="math inline">\(l(\theta,\phi;y) = \log f_{Y}(y;\theta,\phi)\)</span> 为给定样本点 <span class="math inline">\(y\)</span> 的情况下，关于 <span class="math inline">\(\theta\)</span> 和 <span class="math inline">\(\phi\)</span> 的对数似然函数。样本分布 <span class="math inline">\(Y\)</span> 的均值和方差具有如下关系</p>
<p><span class="math display" id="eq:mean-log-lik">\[\begin{equation}
\mathsf{E}\big( \frac{\partial l}{\partial \theta} \big) = 0
\tag{2.3}
\end{equation}\]</span></p>
<p>和</p>
<p><span class="math display" id="eq:variance-log-lik">\[\begin{equation}
\mathsf{E}\big( \frac{\partial^2 l}{\partial \theta^2} \big) + \mathsf{E}\big(\frac{\partial l}{\partial \theta}\big)^2  = 0
\tag{2.4}
\end{equation}\]</span></p>
<p>从 <a href="prepare.html#eq:common-exponential-family">(2.1)</a> 式知</p>
<p><span class="math display">\[ l(\theta,\phi;y) = {y\theta - b(\theta)}/a(\phi) + c(y,\phi) \]</span></p>
<p>因此，</p>
<p><span class="math display" id="eq:partial-log-lik">\[\begin{equation}
\begin{aligned}
\frac{\partial l}{\partial \theta} &amp; = {y - b&#39;(\theta)}/a(\phi)  \\
\frac{\partial^2 l}{\partial \theta^2}  &amp; = - b&#39;&#39;(\theta)/a(\phi)
\end{aligned} \tag{2.5}
\end{equation}\]</span></p>
<p>从 <a href="prepare.html#eq:mean-log-lik">(2.3)</a> 式和 <a href="prepare.html#eq:partial-log-lik">(2.5)</a>，可以得出</p>
<p><span class="math display">\[ 
0 = \mathsf{E}\big( \frac{\partial l}{\partial \theta} \big) = \big\{ \mu - b&#39;(\theta) \big\}/a(\phi)
\]</span></p>
<p>所以</p>
<p><span class="math display">\[ \mathsf{E}(Y) = \mu = b&#39;(\theta) \]</span></p>
<p>根据 <a href="prepare.html#eq:variance-log-lik">(2.4)</a> 式和 <a href="prepare.html#eq:partial-log-lik">(2.5)</a> 式，可得</p>
<p><span class="math display">\[ 0 = - \frac{b&#39;&#39;(\theta)}{a(\phi)} + \frac{\mathsf{Var}(Y)}{a^2(\phi)} \]</span></p>
<p>所以</p>
<p><span class="math display">\[ \mathsf{Var}(Y) = b&#39;&#39;(\theta)a(\phi) \]</span></p>
<p>可见，<span class="math inline">\(Y\)</span> 的方差是两个函数的乘积，一个是 <span class="math inline">\(b&#39;&#39;(\theta)\)</span>， 它仅仅依赖典则参数，被叫做方差函数，另一个是 <span class="math inline">\(a(\phi)\)</span>，它独立于 <span class="math inline">\(\theta\)</span>，仅仅依赖 <span class="math inline">\(\phi\)</span>，方差函数可以看作是 <span class="math inline">\(\mu\)</span> 的函数，记作 <span class="math inline">\(V(\mu)\)</span>。</p>
<p>函数 <span class="math inline">\(a(\phi)\)</span> 通常形如</p>
<p><span class="math display">\[ a(\phi) = \phi/w \]</span></p>
<p>其中 <span class="math inline">\(\phi\)</span> 可由 <span class="math inline">\(\sigma^2\)</span> 表示，故而也叫做发散参数 (dispersion parameter)，是一个与样本观察值相关的常数，<span class="math inline">\(w\)</span> 是已知的权重，随样本观察值变化。对正态分布模型而言，<span class="math inline">\(w\)</span> 的分量是 <span class="math inline">\(m\)</span> 个相互独立的样本观察值的均值，我们有</p>
<p><span class="math display">\[ a(\phi) = \sigma^2/m\]</span></p>
<p>所以，<span class="math inline">\(w = m\)</span>。</p>
<p>根据 <a href="prepare.html#eq:common-exponential-family">(2.1)</a>式，正态、泊松和二项分布的特征见表 <a href="prepare.html#tab:common-characteristics">2.1</a>，其它常见分布见 Peter McCullagh 等 (1989年) <span class="citation">(McCullagh and Nelder <a href="#ref-McCullagh1989">1989</a>)</span>。</p>
<table>
<caption><span id="tab:common-characteristics">表 2.1: </span> 指数族内常见的一元分布的共同特征及符号表示<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></caption>
<colgroup>
<col width="23%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">正态分布</th>
<th align="center">泊松分布</th>
<th align="center">二项分布</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">记号</td>
<td align="center"><span class="math inline">\(N(\mu,\sigma^2)\)</span></td>
<td align="center"><span class="math inline">\(P(\mu)\)</span></td>
<td align="center"><span class="math inline">\(B(m,\pi)/m\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(y\)</span> 取值范围</td>
<td align="center"><span class="math inline">\((-\infty,\infty)\)</span></td>
<td align="center"><span class="math inline">\(0(1)\infty\)</span></td>
<td align="center"><span class="math inline">\(\frac{0(1)m}{m}\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\phi\)</span></td>
<td align="center"><span class="math inline">\(\phi = \sigma^2\)</span></td>
<td align="center"><span class="math inline">\(1\)</span></td>
<td align="center"><span class="math inline">\(1/m\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(b(\theta)\)</span></td>
<td align="center"><span class="math inline">\(\theta^2/2\)</span></td>
<td align="center"><span class="math inline">\(\exp(\theta)\)</span></td>
<td align="center"><span class="math inline">\(\log(1+e^{\theta})\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(c(y;\theta)\)</span></td>
<td align="center"><span class="math inline">\(-\frac{1}{2}\big( \frac{y^2}{\phi} + \log(2\pi\phi) \big)\)</span></td>
<td align="center"><span class="math inline">\(-\log(y!)\)</span></td>
<td align="center"><span class="math inline">\(\log\binom{m}{my}\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mu(\theta) = \mathsf{E}(Y;\theta)\)</span></td>
<td align="center"><span class="math inline">\(\theta\)</span></td>
<td align="center"><span class="math inline">\(\exp(\theta)\)</span></td>
<td align="center"><span class="math inline">\(e^{\theta}/(1+e^{\theta})\)</span></td>
</tr>
<tr class="odd">
<td align="left">联系函数：<span class="math inline">\(\theta(\mu)\)</span></td>
<td align="center">identity</td>
<td align="center">log</td>
<td align="center">logit</td>
</tr>
<tr class="even">
<td align="left">方差函数：<span class="math inline">\(V(\mu)\)</span></td>
<td align="center">1</td>
<td align="center"><span class="math inline">\(\mu\)</span></td>
<td align="center"><span class="math inline">\(\mu(1-\mu)\)</span></td>
</tr>
</tbody>
</table>

</div>
<div id="lse" class="section level2">
<h2><span class="header-section-number">2.2</span> 最小二乘估计</h2>
<p>考虑如下线性模型的最小二乘估计</p>
<p><span class="math display" id="eq:linear-models">\[\begin{equation}
\mathsf{E}\mathbf{Y} = \mathbf{X}\boldsymbol{\beta}; \mathsf{Var}(\mathbf{Y}) = \sigma^2 \mathbf{I}_{n} \tag{2.6}
\end{equation}\]</span></p>
<p>其中， <span class="math inline">\(\mathbf{Y}\)</span> 为 <span class="math inline">\(n \times 1\)</span> 维观测向量， <span class="math inline">\(\mathbf{X}\)</span> 为已知的 <span class="math inline">\(n \times p (p \leq n)\)</span> 阶设计矩阵，<span class="math inline">\(\boldsymbol{\beta}\)</span> 为 <span class="math inline">\(p \times 1\)</span> 维未知参数，<span class="math inline">\(\sigma^2\)</span> 未知，<span class="math inline">\(\mathbf{I}_{n}\)</span> 为 <span class="math inline">\(n\)</span> 阶单位阵。</p>

<div class="definition">
<p><span id="def:least-squares-estimate" class="definition"><strong>定义 2.1  (最小二乘估计)  </strong></span>在模型 <a href="prepare.html#eq:linear-models">(2.6)</a> 中，如果</p>
<p><span class="math display" id="eq:least-squares">\[\begin{equation}
(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}})^{\top}(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}) = \min_{\beta}(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta})^{\top}(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta}) \tag{2.7}
\end{equation}\]</span></p>
则称 <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> 为 <span class="math inline">\(\boldsymbol{\beta}\)</span> 的最小二乘估计 (Least Squares Estimate，简称 LSE)。
</div>


<div class="theorem">
<p><span id="thm:unbiased" class="theorem"><strong>定理 2.1  (最小二乘估计)  </strong></span>若模型 <a href="prepare.html#eq:linear-models">(2.6)</a> 中的 <span class="math inline">\(\mathbf{X}\)</span> 是列满秩的矩阵，则 <span class="math inline">\(\boldsymbol{\beta}\)</span> 的最小二乘估计为</p>
<p><span class="math display">\[
\hat{\boldsymbol{\beta}}_{LS} = ( \mathbf{X}^{\top}\mathbf{X} )^{-1}\mathbf{X}^{\top} \mathbf{Y}, \quad  \mathsf{Var}(\hat{\boldsymbol{\beta}}_{LS}) = \sigma^2 (\mathbf{X}^{\top}\mathbf{X})^{-1}  
\]</span></p>
<p><span class="math inline">\(\sigma^2\)</span> 的最小二乘估计为</p>
<p><span class="math display">\[
\hat{\sigma^2}_{LS} = (\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}_{LS})^{\top}(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}_{LS})/(n - p)
\]</span></p>
<p>若将模型 <a href="prepare.html#eq:linear-models">(2.6)</a> 的条件 <span class="math inline">\(\mathsf{Var}(\mathbf{Y}) = \sigma^2 \mathbf{I}_{n}\)</span> 改为 <span class="math inline">\(\mathsf{Var}(\mathbf{Y}) = \sigma^2 \mathbf{G}\)</span>， <span class="math inline">\(G(&gt;0)\)</span> 为已知正定阵，则<span class="math inline">\(\boldsymbol{\beta}\)</span> 的最小二乘估计为</p>
<p><span class="math display">\[
\tilde{\boldsymbol{\beta}}_{LS} = ( \mathbf{X}^{\top} G^{-1} \mathbf{X})^{-1} \mathbf{X}^{\top} G^{-1} \mathbf{Y} 
\]</span></p>
称 <span class="math inline">\(\tilde{\boldsymbol{\beta}}_{LS}\)</span> 为广义最小二乘估计 (Generalized Least Squares Estimate，简称 GLSE)，特别地，当 <span class="math inline">\(G = \mathrm{diag}(\sigma^2_{1},\ldots,\sigma^2_{n})\)</span>，<span class="math inline">\(\sigma^2_{i},i = 1,\ldots,n\)</span> 已知时，称 <span class="math inline">\(\tilde{\boldsymbol{\beta}}_{LS}\)</span> 为加权最小二乘估计 (Weighted Least Squares Estimate，简称 WLSE)<span class="citation">(王松桂 et al. <a href="#ref-wang2004">2004</a>)</span>
</div>

</div>
<div id="def-mle" class="section level2">
<h2><span class="header-section-number">2.3</span> 极大似然估计</h2>

<div class="definition">
<p><span id="def:maximum-likelihood-estimate" class="definition"><strong>定义 2.2  (极大似然估计)  </strong></span>设 <span class="math inline">\(p(\mathbf{x};\boldsymbol{\theta}),\boldsymbol{\theta} \in \boldsymbol{\Theta}\)</span> 是 <span class="math inline">\((\mathbb{R}^n,\mathscr{P}_{\mathbb{R}^n})\)</span> 上的一族联合密度函数，对给定的 <span class="math inline">\(\mathbf{x}\)</span>，称</p>
<p><span class="math display">\[ L(\boldsymbol{\theta};\mathbf{x}) = kp(\mathbf{x};\boldsymbol{\theta}) \]</span></p>
<p>为 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的似然函数，其中 <span class="math inline">\(k &gt; 0\)</span> 是不依赖于 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的量，常取 <span class="math inline">\(k=1\)</span>。进一步，若存在 <span class="math inline">\((\mathbb{R}^n,\mathscr{P}_{\mathbb{R}^n})\)</span> 到 <span class="math inline">\((\boldsymbol{\Theta},\mathscr{P}_{\boldsymbol{\Theta}})\)</span> 的统计量 <span class="math inline">\(\hat{\boldsymbol{\theta}}(\mathbf{x})\)</span> 使</p>
<p><span class="math display">\[ L(\hat{\boldsymbol{\theta}}(\mathbf{x});\mathbf{x}) = \sup_{\boldsymbol{\theta}} L(\boldsymbol{\theta};\mathbf{x}) \]</span></p>
则 <span class="math inline">\(\hat{\boldsymbol{\theta}}(\mathbf{x})\)</span> 称为 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的一个极大似然估计(Maximum Likelihood Eestimate，简称 MLE)。
</div>

<p>概率密度函数很多可以写成具有指数函数的形式，如指数族，采用似然函数的对数通常更为简便。称</p>
<p><span class="math display">\[ l(\boldsymbol{\theta},\mathbf{x}) = \ln L(\boldsymbol{\theta},\mathbf{x}) \]</span></p>
<p>为 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的对数似然函数。对数变换是严格单调的，所以 <span class="math inline">\(l(\boldsymbol{\theta},\mathbf{x})\)</span> 与 <span class="math inline">\(L(\boldsymbol{\theta},\mathbf{x})\)</span> 的极大值是等价的。当 MLE 存在时，寻找 MLE 的常用方法是求导数。如果 <span class="math inline">\(\hat{\boldsymbol{\theta}}(\mathbf{x})\)</span> 是 <span class="math inline">\(\boldsymbol{\Theta}\)</span> 的内点，则 <span class="math inline">\(\hat{\boldsymbol{\theta}}(\mathbf{x})\)</span> 是下列似然方程组</p>
<p><span class="math display" id="eq:likelihood-equations">\[\begin{equation}
\partial l(\boldsymbol{\theta},\mathbf{x})/ \partial \boldsymbol{\theta}_{i} = 0, \quad i = 1,\ldots, m \tag{2.8}
\end{equation}\]</span></p>
<p>的解。<span class="math inline">\(p(\mathbf{x};\boldsymbol{\theta})\)</span> 属于指数族时，似然方程组 <a href="prepare.html#eq:likelihood-equations">(2.8)</a> 的解唯一。</p>

<div class="theorem">
<p><span id="thm:consistency" class="theorem"><strong>定理 2.2  (相合性)  </strong></span>设 <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span> 是来自概率密度函数 <span class="math inline">\(p(x;\theta)\)</span> 的一个样本，叙述简单起见，考虑单参数情形，参数空间 <span class="math inline">\(\boldsymbol{\Theta}\)</span> 是一个开区间，<span class="math inline">\(l(\theta;x) = \sum_{i=1}^{n}\ln p(x_{i};\theta)\)</span>。</p>
若 <span class="math inline">\(\ln (p;\theta)\)</span> 在 <span class="math inline">\(\boldsymbol{\Theta}\)</span> 上可微，且 <span class="math inline">\(p(x;\theta)\)</span> 是可识别的（即 <span class="math inline">\(\forall \theta_1 \neq \theta_2, \{x: p(x;\theta_1) \neq p(x; \theta_2)\}\)</span> 不是零测集），则似然方程 <a href="prepare.html#eq:likelihood-equations">(2.8)</a> 在 <span class="math inline">\(n \to \infty\)</span> 时，以概率 1 有解，且此解关于 <span class="math inline">\(\theta\)</span> 是相合的。
</div>


<div class="theorem">
<p><span id="thm:asymptotic-normality" class="theorem"><strong>定理 2.3  (渐近正态性)  </strong></span>假设 <span class="math inline">\(\boldsymbol{\Theta}\)</span> 为开区间，概率密度函数 <span class="math inline">\(p(x;\theta), \theta \in \boldsymbol{\Theta}\)</span> 满足</p>
<ol style="list-style-type: decimal">
<li>在参数真值 <span class="math inline">\(\theta_{0}\)</span> 的邻域内，<span class="math inline">\(\partial \ln p/\partial \theta, \partial^2 \ln p/\partial \theta^2, \partial^3 \ln p/\partial \theta^3\)</span> 对所有的 <span class="math inline">\(x\)</span> 都存在；</li>
<li>在参数真值 <span class="math inline">\(\theta_{0}\)</span> 的邻域内，<span class="math inline">\(| \partial^3 \ln p/\partial \theta^3 | \leq H(x)\)</span>，且 <span class="math inline">\(\mathsf{E}H(x) &lt; \infty\)</span>；</li>
<li>在参数真值 <span class="math inline">\(\theta_{0}\)</span> 处，</li>
</ol>
<p><span class="math display">\[\begin{equation} 
\mathsf{E}_{\theta_{0}} \big[ \frac{ p&#39;(x,\theta_{0}) }{ p(x,\theta_{0}) } \big] = 0, \quad
\mathsf{E}_{\theta_{0}} \big[ \frac{ p&#39;&#39;(x,\theta_{0}) }{ p(x,\theta_{0}) } \big] = 0, \quad
I(\theta_{0}) = \mathsf{E}_{\theta_{0}} \big[ \frac{ p&#39;(x,\theta_{0}) }{ p(x,\theta_{0}) } \big]^{2} &gt; 0
\end{equation}\]</span></p>
<p>其中撇号表示对 <span class="math inline">\(\theta\)</span> 的微分。记 <span class="math inline">\(\hat{\theta}_{n}\)</span> 为 <span class="math inline">\(n \to \infty\)</span> 时，似然方程组的相合解，则</p>
<span class="math display">\[ \sqrt{n}(\hat{\theta}_{n} - \theta_{0}) \longrightarrow  \mathcal{N}(\mathbf{0},I^{-1}(\theta))\]</span>
</div>

</div>
<div id="section-2.4" class="section level2">
<h2><span class="header-section-number">2.4</span> 随机过程的连续性和可微性</h2>
<p>为记号简便起见，考虑一维空间下，随机过程 <span class="math inline">\(S(x)\)</span> 的均方连续性和可微性。</p>

<div class="definition">
<p><span id="def:continuous" class="definition"><strong>定义 2.3  (连续性)  </strong></span>随机过程 <span class="math inline">\(S(x)\)</span> 满足</p>
<p><span class="math display">\[ \lim_{h \to 0} \mathsf{E}\big[ \{S(x + h) - S(x)\}^{2} \big] = 0 \]</span></p>
则称 <span class="math inline">\(S(x)\)</span> 是均方连续(mean-square continuous)的。
</div>


<div class="definition">
<p><span id="def:differentiable" class="definition"><strong>定义 2.4  (可微性)  </strong></span>随机过程 <span class="math inline">\(S(x)\)</span> 满足</p>
<p><span class="math display">\[ \lim_{h \to 0} \mathsf{E} \big[ \{ \frac{S(x+h) - S(x)}{h} - S&#39;(x) \}^2 \big] = 0 \]</span></p>
则称 <span class="math inline">\(S(x)\)</span> 是均方可微的，并且 <span class="math inline">\(S&#39;(x)\)</span> 就是均方意义下的一阶导数。如果 <span class="math inline">\(S&#39;(x)\)</span> 是均方可微的，则 <span class="math inline">\(S(x)\)</span> 是二次均方可微的，随机过程 <span class="math inline">\(S(x)\)</span> 的高阶均方可微性可类似定义。
</div>

<p>Bartlett (1955 年) <span class="citation">(Bartlett <a href="#ref-Bartlett1955">1955</a>)</span> 得到如下结论</p>

<div class="theorem">
<span id="thm:stationary-mean-square-properties" class="theorem"><strong>定理 2.4  (平稳随机过程的可微性)  </strong></span>自相关函数为 <span class="math inline">\(\rho(u)\)</span> 的平稳随机过程是 <span class="math inline">\(k\)</span> 次均方可微 (mean-square differentiable) 的，当且仅当 <span class="math inline">\(\rho(u)\)</span> 在 <span class="math inline">\(u = 0\)</span> 处是 <span class="math inline">\(2k\)</span> 次可微的。
</div>

</div>
<div id="stationary-gaussian-process" class="section level2">
<h2><span class="header-section-number">2.5</span> 平稳高斯过程</h2>
<p>一般地，空间高斯过程 <span class="math inline">\(\mathcal{S} = \{S(x),x\in\mathbb{R}^2\}\)</span> 必须满足条件：任意给定一组空间位置 <span class="math inline">\(x_1,x_2,\ldots,x_n, \forall x_{i} \in \mathbb{R}^2\)</span>， 每个位置上对应的随机变量 <span class="math inline">\(S(x_i), i = 1,2,\ldots,n\)</span> 的联合分布 <span class="math inline">\(\mathcal{S} = \{S(x_1), S(x_2),\ldots,S(x_n)\}\)</span> 是多元高斯分布，其由均值 <span class="math inline">\(\mu(x) = \mathrm{E}[S(x)]\)</span> 和协方差 <span class="math inline">\(G_{ij} = \gamma(x_i,x_j) = \mathrm{Cov}\{S(x_i),S(x_j)\}\)</span> 完全确定，即 <span class="math inline">\(\mathcal{S} \sim \mathrm{MVN}(\mu_{S},G)\)</span></p>
<p>平稳空间高斯过程需要空间高斯过程满足平稳性条件：其一， <span class="math inline">\(\mu(x) = \mu, \forall x \in \mathbb{R}^2\)</span>， 其二，自协方差函数 <span class="math inline">\(\gamma(x_i,x_j) = \gamma(u),u=\|x_{i} - x_{j}\|\)</span>。 可见均值 <span class="math inline">\(\mu\)</span> 是一个常数， 而自协方差函数 <span class="math inline">\(\gamma(x_i,x_j)\)</span> 只与空间距离有关。 注意到平稳高斯过程 <span class="math inline">\(\mathcal{S}\)</span> 的方差是一个常数，即 <span class="math inline">\(\sigma^2 = \gamma(0)\)</span>， 然后可以定义自相关函数 <span class="math inline">\(\rho(u) = \gamma(u)/\sigma^2\)</span>， 并且 <span class="math inline">\(\rho(u)\)</span> 满足对称性， <span class="math inline">\(\rho(u) = \rho(-u)\)</span>， 因为对 <span class="math inline">\(\forall u, \mathrm{Corr}\{S(x),S(x-u)\} = \mathrm{Corr}\{S(x-u), S(x)\} = \mathrm{Corr}\{S(x),S(x+u)\}\)</span>， 这里的第二个等式是根据平稳性得来的， 根据协方差的定义不难验证。 在本论文中如果不特别说明， 平稳就指上述协方差意义下的平稳， 这种平稳性条件广泛应用于空间统计数据建模。</p>
</div>
<div id="Modified-Bessel-functions" class="section level2">
<h2><span class="header-section-number">2.6</span> 修正的第三类贝塞尔函数</h2>
<p>空间过程的协方差函数是梅隆族时，需要用到修正的第三类贝塞尔函数 <span class="math inline">\(\mathcal{K}_{\kappa}(u)\)</span>，它是修正的贝塞尔方程的解 <span class="citation">(Abramowitz and Stegun <a href="#ref-Abramowitz1972">1972</a>)</span>，函数形式如下</p>
<p><span class="math display" id="eq:besselK-function">\[\begin{equation}
\begin{aligned}
I_{-\kappa}(u) &amp; =  \sum_{m=0}^{\infty} \frac{1}{m!\Gamma(m + \kappa + 1)} \big(\frac{u}{2}\big)^{2m + \kappa} \\
\mathcal{K}_{\kappa}(u) &amp; = \frac{\pi}{2} \frac{I_{-\kappa}(u) - I_{\kappa}(u)}{\sin (\kappa \pi)}
\end{aligned} \tag{2.9}
\end{equation}\]</span></p>
<p>其中 <span class="math inline">\(u \geq 0\)</span>，<span class="math inline">\(\kappa \in \mathbb{R}\)</span>，如果 <span class="math inline">\(\kappa \in \mathbb{Z}\)</span>，则取该点的极限值，实际上 R 内置的函数 <code>besselK</code> 可以计算 <span class="math inline">\(\mathcal{K}_{\kappa}(u)\)</span> <span class="citation">(Campbell <a href="#ref-Campbell1980">1980</a>)</span></p>
<div class="figure" style="text-align: center"><span id="fig:Bessel-function"></span>
<img src="figures/bessel.png" alt="贝塞尔函数图像" width="70%" />
<p class="caption">
图 2.1: 贝塞尔函数图像
</p>
</div>
</div>
<div id="Laplace-approximation" class="section level2">
<h2><span class="header-section-number">2.7</span> 拉普拉斯近似</h2>
<p>先回顾一下基本的泰勒展开，一个函数可以在点 <span class="math inline">\(a\)</span> 处展开成和的形式，有时候是无穷多项，可以使用其中的有限项最为近似，通常会使用前三项，即到达二阶导的位置。</p>
<p><span class="math display">\[
f(x) = f(a) + \frac{f&#39;(a)}{1!}(x-a) + \frac{f&#39;&#39;(a)}{2!}(x-a)^2 + \frac{f&#39;&#39;&#39;(a)}{3!}(x-a)^3 + \ldots
\]</span></p>
<p>以基本的抛物线为例， <span class="math inline">\(f(x) = x^2\)</span>，在 <span class="math inline">\(a = 2\)</span> 处展开</p>
<p><span class="math display">\[ f(x) = x^2, \quad f&#39;(x) = 2x, \quad f&#39;&#39;(x) = 2, \quad f&#39;&#39;&#39;(x) = 0 \]</span></p>
<p>因此，</p>
<p><span class="math display">\[ f(x) = x^2 = 2^2 + 2(2)(x-2) + \frac{2}{2}(x-2)^2 \]</span></p>
<p>拉普拉斯近似用正态分布来估计任意分布，它使用泰勒展开的前三项近似 <span class="math inline">\(\log g(x)\)</span>，展开的位置是 <span class="math inline">\(\hat{x}\)</span>，则</p>
<p><span class="math display">\[
\log g(x) \approx \log g(\hat{x}) + \frac{\partial \log g(\hat{x})}{\partial x} (x - \hat{x}) + \frac{\partial^2 \log g(\hat{x})}{2\partial x^2} (x - \hat{x})^2
\]</span></p>
<p>在函数 <span class="math inline">\(g(x)\)</span> 的极值点 <span class="math inline">\(\hat{x}\)</span> 展开， <span class="math inline">\(x = \hat{x}\)</span> 一阶导是 0，用曲率去估计方差是 <span class="math inline">\(\hat{\sigma}^2 = -1/\frac{\partial^2 \log g(\hat{x})}{2\partial x^2}\)</span>，再重写上述近似</p>
<p><span class="math display">\[ \log g(x) \approx \log g(\hat{x}) - \frac{1}{2\hat{\sigma}^2} (x - \hat{x})^2 \]</span></p>
<p>现在，用这个结果做正态近似，将上式两端取指数和积分，移去常数项</p>
<p><span class="math display">\[
\int g(x) \mathrm{d}x = \int \exp[\log g(x)] \mathrm{d}x \approx \mathrm{constant} \int \exp[- \frac{(x - \hat{x})^2}{2\hat{\sigma}^2}] \mathrm{d}x
\]</span></p>
<p>拉普拉斯方法用正态分布近似分布 <span class="math inline">\(f(x)\)</span>， 其均值 <span class="math inline">\(\hat{x}\)</span>，可以通过求解 <span class="math inline">\(f&#39;(x) = 0\)</span> 获得，方差 <span class="math inline">\(\hat{\sigma}^2 = -1/f&#39;&#39;(\hat{x})\)</span></p>
<p>以卡方分布 <span class="math inline">\(\chi^2\)</span> 为例，</p>
<p><span class="math display">\[\begin{align*}
    f(x; k) &amp; = \frac{ x^{k/2-1} \mathrm{e}^{-x/2} }{ 2^{k/2}\Gamma(k/2) }, x \geq 0 \\
  \log f(x) &amp; = (k/2 - 1) \log x - x/2 \\
 \log f&#39;(x) &amp; = (k/2-1)/x - 1/2 = 0 \\
\log f&#39;&#39;(x) &amp; = -(k/2-1)/x^2
\end{align*}\]</span></p>
<p>所以</p>
<p><span class="math display">\[ \chi_{k}^2 \overset{LA}{\sim}  N(\hat{x} = k-2, \hat{\sigma}^2 = 2(k-2)) \]</span></p>
<p>自由度越大，近似效果越好，对于多元分布的情况不难推广，使用多元泰勒展开和黑塞矩阵即可表示。并且参数集 <span class="math inline">\(\theta\)</span> 有唯一的极大值点 <span class="math inline">\(\hat{\theta}\)</span> <span class="citation">(Tierney and Kadane <a href="#ref-Tierney1986">1986</a>)</span></p>
</div>
<div id="Jeffreys-prior" class="section level2">
<h2><span class="header-section-number">2.8</span> Jeffreys 先验分布</h2>
<p>设 <span class="math inline">\(\mathbf{x} = (x_1,\ldots,x_n)\)</span> 是来自密度函数 <span class="math inline">\(p(x|\theta)\)</span> 的一个样本，其中 <span class="math inline">\(\boldsymbol{\theta} = (\theta_1,\ldots,\theta_p)\)</span> 是 <span class="math inline">\(p\)</span> 维参数向量。在对 <span class="math inline">\(\boldsymbol{\theta}\)</span> 无任何先验信息可用时， Jeffreys (1961年)利用变换群和 Harr 测度导出 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的无信息先验分布可用 Fisher 信息阵的行列式的平方根表示。这种无信息先验分布常称为 Jeffreys 先验分布。其求取步骤如下：</p>
<ol style="list-style-type: decimal">
<li>写出样本的对数似然函数 <span class="math inline">\(l(\boldsymbol{\theta}|x) = \sum_{i=1}^{n}\ln p(x_i | \theta)\)</span>；</li>
<li>算出参数 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的 Fisher 信息阵
<span class="math display">\[\mathbf{I}(\boldsymbol{\theta}) = \mathsf{E}_{x|\theta} \big( - \frac{\partial^2 l}{\partial \theta_i \partial \theta_j} \big)_{i,j=1,\ldots,p}\]</span>
在单参数场合， <span class="math inline">\(\mathbf{I}(\theta) = \mathsf{E}_{x|\theta} \big( - \frac{\partial^2 l}{\partial \theta^2} \big)\)</span>；</li>
<li><span class="math inline">\(\boldsymbol{\theta}\)</span> 的无信息先验密度函数为 <span class="math inline">\(\pi(\boldsymbol{\theta}) = [\det \mathbf{I}(\theta) ]^{1/2}\)</span>，在单参数场合， <span class="math inline">\(\pi(\theta) = [\mathbf{I}(\theta) ]^{1/2}\)</span></li>
</ol>
</div>
<div id="bayes-methods" class="section level2">
<h2><span class="header-section-number">2.9</span> 贝叶斯定理与先验分布</h2>
<p><span class="todo">非信息先验分布，扁平先验 flat prior，模糊先验</span></p>
<p>以标准线性模型为例介绍贝叶斯分析及其基本概念 <span class="citation">(Rasmussen and Williams <a href="#ref-Rasmussen2006">2006</a>)</span>，为什么不用 RMSE 均方误差，WAIC pDIC 模型选择 loo K-CV</p>
<p>贝叶斯定理 <a href="prepare.html#fig:bayes-theorem">2.2</a> 贝叶斯定理 <a href="prepare.html#eq:bayes-theorem">(2.10)</a></p>
<div class="figure" style="text-align: center"><span id="fig:bayes-theorem"></span>
<img src="figures/bayes-theorem.png" alt="贝叶斯定理" width="70%" />
<p class="caption">
图 2.2: 贝叶斯定理
</p>
</div>
<p>作为铺垫，先结合 SGLMM 模型介绍一下贝叶斯定理，其中，<span class="math inline">\(\boldsymbol{\theta}\)</span> 代表 SGLMM 模型中的参数，<span class="math inline">\(\mathbf{Y}\)</span> 是响应变量对应的观察值。</p>
<p><span class="math display" id="eq:bayes-theorem">\[\begin{align}
\begin{array}{rcll}
p(\boldsymbol{\theta}|\mathbf{Y})  &amp; =  &amp; \displaystyle \frac{p(\boldsymbol{\theta},\mathbf{Y})}{p(\mathbf{Y})}
&amp; \mbox{ [条件概率定义]}
\\[16pt]
&amp; = &amp; \displaystyle \frac{p(\mathbf{Y}|\boldsymbol{\theta}) p(\boldsymbol{\theta})}{p(\mathbf{Y})}
&amp; \mbox{ [链式法则]}
\\[16pt]
&amp; = &amp; \displaystyle \frac{p(\mathbf{Y}|\boldsymbol{\theta})p(\boldsymbol{\theta})}{\int_{\Theta}p(\mathbf{Y},\boldsymbol{\theta})d\boldsymbol{\theta}}
&amp; \mbox{ [全概率公式]}
\\[16pt]
&amp; = &amp; \displaystyle \frac{p(\mathbf{Y}|\boldsymbol{\theta})p(\boldsymbol{\theta})}{\int_{\Theta}p(\mathbf{Y}|\boldsymbol{\theta})p(\boldsymbol{\theta})d\boldsymbol{\theta}}
&amp; \mbox{ [链式法则]}
\\[16pt]
&amp; \propto &amp; \displaystyle p(\mathbf{Y}|\boldsymbol{\theta})p(\boldsymbol{\theta})
&amp; \mbox{ [$\mathbf{Y}$ 已知]}
\end{array} \tag{2.10}
\end{align}\]</span></p>
</div>
<div id="Curse-of-Dimensionality" class="section level2">
<h2><span class="header-section-number">2.10</span> 维数灾难与蒙特卡罗积分</h2>
<p>一般地，混合效应模型的统计推断总是不可避免的要面对高维积分，处理高维积分的方法一个是寻找近似方法避免求积分，一个是寻找有效的随机模拟方法直接求积分。这里，介绍蒙特卡罗方法求积分，以计算 <span class="math inline">\(N\)</span> 维超立方体的内切球的体积为例说明。</p>
<p>假设我们有一个 <span class="math inline">\(N\)</span> 维超立方体，其中心在坐标 <span class="math inline">\(\mathbf{0} = (0,\ldots,0)\)</span>。超立方体在点 <span class="math inline">\((\pm 1/2,\ldots,\pm 1/2)\)</span>，有 <span class="math inline">\(2^{N}\)</span> 个角落，超立方体边长是1，<span class="math inline">\(1^{N}=1\)</span>，所以它的体积是1。</p>
<p>如果 <span class="math inline">\(N=1\)</span>，超立方体是一条从 <span class="math inline">\(-\frac{1}{2}\)</span> 到 <span class="math inline">\(\frac{1}{2}\)</span> 的单位长度的线，如果 <span class="math inline">\(N=2\)</span>，超立方体是一个单位正方形，对角是 <span class="math inline">\(\left( -\frac{1}{2}, -\frac{1}{2} \right)\)</span> 和 <span class="math inline">\(\left( \frac{1}{2}, \frac{1}{2} \right)\)</span>，如果 <span class="math inline">\(N=3\)</span>，超立方体就是单位体积的立方体，对角是 <span class="math inline">\(\left( -\frac{1}{2}, -\frac{1}{2}, -\frac{1}{2} \right)\)</span> 和 <span class="math inline">\(\left( \frac{1}{2}, \frac{1}{2}, \frac{1}{2} \right)\)</span>，依此类推，<span class="math inline">\(N\)</span> 维超立方体体积是1，对角是 <span class="math inline">\(\left( -\frac{1}{2}, \ldots, -\frac{1}{2} \right)\)</span> 和 <span class="math inline">\(\left( \frac{1}{2}, \ldots, \frac{1}{2} \right)\)</span></p>
<p>现在，考虑 <span class="math inline">\(N\)</span> 维超立方体的内切球，我们把它称为 <span class="math inline">\(N\)</span> 维超球，它的中心在原点，半径是 <span class="math inline">\(\frac{1}{2}\)</span>。我们说点 <span class="math inline">\(y\)</span> 在超球内，意味着它到原点的距离小于半径，即 <span class="math inline">\(\| y \| &lt; \frac{1}{2}\)</span>。</p>
<p>一维情形下，超球是从的线，包含了整个超立方体。二维情形下，超球是中心在原点，半径为 <span class="math inline">\(\frac{1}{2}\)</span> 的圆。三维情形下，超球是立方体的内切球。</p>
<p>我们知道单位超立方体的体积是1，但是其内的内切球的体积是多少呢？我们已经学过如何去定义一个积分计算半径为 <span class="math inline">\(r\)</span> 的二维球（即圆）的体积（即面积）是 <span class="math inline">\(\pi r^2\)</span>，三维情形下，内切球是 <span class="math inline">\(\frac{4}{3}\pi r^3\)</span>。但是更高维的欧式空间里，内切球的体积是多少呢？</p>
<p>我们当然可以去计算越来越复杂的多重积分，但是这里我们介绍采样的方法去计算积分，即所谓的蒙特卡罗方法，由乌拉姆 (S. Ulam)、冯<span class="math inline">\(\cdot\)</span>诺依曼(J. von Neumann) 和梅特罗波利斯 (N. Metropolis) 等 在美国核武器研究实验室创立，当时正值二战期间，为了研制原子弹，出于保密的需要，与随机模拟相关的技术就代号蒙特卡罗。现在，蒙特卡罗方法占据现代统计计算的核心地位，特别是与贝叶斯相关的领域。</p>
<p>用蒙特卡罗方法去计算单位超立方体内的超球，首先我们需要在单位超立方体内产生随机点，然后计算落在超球内点的比例，即超球的体积。随着点的数目增加，估计的体积会收敛到真实的体积。因为这些点都独立同均匀分布，根据中心极限定理，误差下降的比率是 <span class="math inline">\(\mathcal{O}\left( 1 / \sqrt{n} \right)\)</span>，这也意味着每增加一个小数点的准确度，样本量要增加 100 倍。</p>
<p>表 <a href="prepare.html#tab:calculate-volume-of-hyperball">2.2</a> 列出了前10维超球的体积，随着维数的增加，超球的体积迅速变小，超立方体内随机点的个数是 100000。这里有一个反直观的现象，内切球的体积竟然随着维数的增加变小，并且在10维的情形下，内切球的体积已不到超立方体的 0.3%。</p>
<table>
<caption><span id="tab:calculate-volume-of-hyperball">表 2.2: </span> 前10维单位超立方体内切球的体积（已经四舍五入保留小数点后三位）</caption>
<thead>
<tr class="header">
<th align="left">维数</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
<th align="center">7</th>
<th align="center">8</th>
<th align="center">9</th>
<th align="center">10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">体积</td>
<td align="center">1.000</td>
<td align="center">0.784</td>
<td align="center">0.525</td>
<td align="center">0.307</td>
<td align="center">0.166</td>
<td align="center">0.081</td>
<td align="center">0.037</td>
<td align="center">0.016</td>
<td align="center">0.006</td>
<td align="center">0.0027</td>
</tr>
</tbody>
</table>
</div>
<div id="Samplers" class="section level2">
<h2><span class="header-section-number">2.11</span> 采样器与 Stan</h2>
<p>随机模拟的基础是有高质量的伪随机数，如何生成和检验伪随机数的质量参见黄湘云的文章 <span class="citation">(黄湘云 <a href="#ref-Huang2017COS">2017</a>)</span>。通过随机模拟的方式从总体中获取样本，需要一个抽样（也叫采样）的过程，不同的采样算法（也叫采样器）在适用范围和采样效率方面有不同。在贝叶斯计算中，常用的采样器有 Gibbs， Metropolis 和汉密尔顿蒙特卡罗 (Hamiltonian Monte Carlo，简称 HMC) 三类。</p>
<p>Matthew D. Hoffman 和 Andrew Gelman (2014年) <span class="citation">(Hoffman and Gelman <a href="#ref-hoffman2014">2014</a>)</span> 提出的 No-U-Turn 采样器属于 HMC 方法 衍生的采样器。</p>
<p>Stan 是一门基于 C++ 的高级编程语言，用户只需提供数据、模型和参数初值，目标后验分布的 Markov 链的模拟过程是自动实现的。除了可以完全在 Stan 脚本中写模型外，Stan 还提供其他编程语言的接口，如 R，Python 和 MATLAB 等，使得熟悉其他编程语言的用户也可以比较方便地调用。与 Python、R 这类解释型编程语言不同， Stan 代码需要先翻译成 C++ 代码，然后编译执行。</p>
<p>Donald B. Rubin (1981年) <span class="citation">(Rubin <a href="#ref-Rubin1981">1981</a>)</span> 分析了 Donald L. Alderman 和 Donald E. Powers <span class="citation">(Alderman and Powers <a href="#ref-Alderman1980">1980</a>)</span> 收集的原始数据，得出表 <a href="prepare.html#tab:eight-high-schools">2.3</a>， Andrew Gelman 和 John B. Carlin 等 (2003年) <span class="citation">(Gelman et al. <a href="#ref-Gelman2003">2003</a>)</span> 建立分层正态模型 <a href="prepare.html#eq:hierarchical-normal-models">(2.11)</a> 分析 Eight Schools 数据集，这里再次以该数据集和模型为例介绍 Stan 的使用和算法实现。</p>
<p><span class="math display" id="eq:hierarchical-normal-models">\[\begin{equation}
\begin{aligned}
     \mu &amp; \sim \mathcal{N}(0,5) \\
    \tau &amp; \sim \text{Half-Cauchy}(0,5) \\
p(\mu,\tau) &amp; \propto 1 \\
  \eta_i &amp; \sim \mathcal{N}(0,1) \\
\theta_i &amp;  =   \mu + \tau \cdot \eta_i \\
     y_i &amp; \sim \mathcal{N}(\theta_i,\sigma^2_{i})
\end{aligned}
\tag{2.11}
\end{equation}\]</span></p>
<p>由美国教育考试服务调查搜集，用以分析不同的辅导项目对学生考试分数的影响，调查结果用来帮助高校招生。分别随机调查了 8 所高中，输出变量是一个分数，培训效应的估计 <span class="math inline">\(y_j\)</span>，其样本方差 <span class="math inline">\(\sigma^2_j\)</span>，数据集见表 <a href="prepare.html#tab:eight-high-schools">2.3</a>。</p>
<table>
<caption><span id="tab:eight-high-schools">表 2.3: </span> Eight Schools 数据集</caption>
<thead>
<tr class="header">
<th align="center">School</th>
<th align="center">A</th>
<th align="center">B</th>
<th align="center">C</th>
<th align="center">D</th>
<th align="center">E</th>
<th align="center">F</th>
<th align="center">G</th>
<th align="center">H</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(y_i\)</span></td>
<td align="center">28</td>
<td align="center">8</td>
<td align="center">-3</td>
<td align="center">7</td>
<td align="center">-1</td>
<td align="center">1</td>
<td align="center">18</td>
<td align="center">12</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\sigma_i\)</span></td>
<td align="center">15</td>
<td align="center">10</td>
<td align="center">16</td>
<td align="center">11</td>
<td align="center">9</td>
<td align="center">11</td>
<td align="center">10</td>
<td align="center">18</td>
</tr>
</tbody>
</table>
<p>分层正态模型可以在 Stan 中写成如下形式，在工作目录下把它保存为 <code>8schools.stan</code></p>
<pre><code>// saved as 8schools.stan
data {
  int&lt;lower=0&gt; J; // number of schools 
  real y[J]; // estimated treatment effects
  real&lt;lower=0&gt; sigma[J]; // s.e. of effect estimates 
}
parameters {
  real mu; // population mean
  real&lt;lower=0&gt; tau; // population sd
  real eta[J]; // school-level errors
}
transformed parameters {
  real theta[J];  // schools effects
  for (j in 1:J)
    theta[j] = mu + tau * eta[j];
  // theta = mu + tau*eta;
}
model {
  // set prior for mu or uniform prior distribution default
  // target += normal_lpdf(mu  | 0, 10); 
  // target += cauchy_lpdf(tau | 0, 25); # the same as mu
  target += normal_lpdf(eta | 0, 1);
  target += normal_lpdf(y | theta, sigma); // target distribution
  // y ~ normal(theta, sigma);
}</code></pre>
<p>上述 Stan 代码的第一段提供数据：学校的数目 <span class="math inline">\(J\)</span>，估计值 <span class="math inline">\(y_1,\ldots,y_{J}\)</span>，标准差 <span class="math inline">\(\sigma_1,\ldots,\sigma_{J}\)</span>，数据类型可以是整数、实数，结构可以是向量，或更一般的数组，还可以带约束，如在这个模型中 <span class="math inline">\(J\)</span> 限制为非负， <span class="math inline">\(\sigma_{J}\)</span> 必须是正的，另外两个反斜杠 // 表示注释。</p>
<p>第二段代码声明参数：模型中的待估参数，学校总体的效应 <span class="math inline">\(\theta_j\)</span>，均值 <span class="math inline">\(\mu\)</span>，标准差 <span class="math inline">\(\tau\)</span>，学校水平上的误差 <span class="math inline">\(\eta\)</span> 和效应 <span class="math inline">\(\theta\)</span>。在这个模型中，用 <span class="math inline">\(\mu,\tau,\eta\)</span> 表示 <span class="math inline">\(\theta\)</span> 而不是直接声明 <span class="math inline">\(\theta\)</span> 作一个参数，通过这种参数化，采样器的运行效率会提高，还应该尽量使用向量化操作代替 for 循环语句。</p>
<p>最后一段是模型：稍微注意的是，正文中正态分布 <span class="math inline">\(N(\cdot,\cdot)\)</span> 中后一个位置是方差，而 Stan 代码中使用的是标准差。<code>target += normal_lpdf(y | theta, sigma)</code> 和 <code>y ~ normal(theta, sigma)</code> 对模型的贡献是一样的，都使用正态分布的对数概率密度函数，只是后者扔掉了对数密度函数的常数项而已，这对于 Stan 的采样、近似或优化算法没有影响 <span class="citation">(Carpenter et al. <a href="#ref-Stan2017JSS">2017</a>)</span>。</p>
<p>算法运行的硬件环境是 16 核 32 线程主频 2.8 GHz 英特尔至强 E5-2680 处理器，系统环境 CentOS 7，R 软件版本 3.5.1，RStan 版本 2.17.3。</p>
<p>HMC算法参数主要设置了4条链，每条链迭代 10000 次，为复现模型结果随机数种子设为 2018</p>
<table>
<caption><span id="tab:eight-schools-output">表 2.4: </span> 对 Eight Schools 数据集建立分层正态模型 <a href="prepare.html#eq:hierarchical-normal-models">(2.11)</a>，采用 HMC 算法估计模型参数值</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">mean</th>
<th align="right">se_mean</th>
<th align="right">sd</th>
<th align="right">2.5%</th>
<th align="right">25%</th>
<th align="right">50%</th>
<th align="right">75%</th>
<th align="right">97.5%</th>
<th align="right">n_eff</th>
<th align="right">Rhat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\mu\)</span></td>
<td align="right">7.99</td>
<td align="right">0.05</td>
<td align="right">5.02</td>
<td align="right">-1.65</td>
<td align="right">4.75</td>
<td align="right">7.92</td>
<td align="right">11.15</td>
<td align="right">18.10</td>
<td align="right">8455</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\tau\)</span></td>
<td align="right">6.47</td>
<td align="right">0.06</td>
<td align="right">5.44</td>
<td align="right">0.22</td>
<td align="right">2.45</td>
<td align="right">5.18</td>
<td align="right">9.07</td>
<td align="right">20.50</td>
<td align="right">7375</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\eta_1\)</span></td>
<td align="right">0.40</td>
<td align="right">0.01</td>
<td align="right">0.93</td>
<td align="right">-1.49</td>
<td align="right">-0.21</td>
<td align="right">0.42</td>
<td align="right">1.02</td>
<td align="right">2.19</td>
<td align="right">16637</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\eta_2\)</span></td>
<td align="right">0.00</td>
<td align="right">0.01</td>
<td align="right">0.87</td>
<td align="right">-1.73</td>
<td align="right">-0.58</td>
<td align="right">0.00</td>
<td align="right">0.57</td>
<td align="right">1.70</td>
<td align="right">16486</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\eta_3\)</span></td>
<td align="right">-0.20</td>
<td align="right">0.01</td>
<td align="right">0.93</td>
<td align="right">-1.99</td>
<td align="right">-0.82</td>
<td align="right">-0.20</td>
<td align="right">0.41</td>
<td align="right">1.66</td>
<td align="right">20000</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\eta_4\)</span></td>
<td align="right">-0.04</td>
<td align="right">0.01</td>
<td align="right">0.88</td>
<td align="right">-1.80</td>
<td align="right">-0.60</td>
<td align="right">-0.04</td>
<td align="right">0.53</td>
<td align="right">1.74</td>
<td align="right">20000</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\eta_5\)</span></td>
<td align="right">-0.36</td>
<td align="right">0.01</td>
<td align="right">0.88</td>
<td align="right">-2.06</td>
<td align="right">-0.94</td>
<td align="right">-0.38</td>
<td align="right">0.20</td>
<td align="right">1.42</td>
<td align="right">15489</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\eta_6\)</span></td>
<td align="right">-0.22</td>
<td align="right">0.01</td>
<td align="right">0.90</td>
<td align="right">-1.96</td>
<td align="right">-0.82</td>
<td align="right">-0.23</td>
<td align="right">0.37</td>
<td align="right">1.57</td>
<td align="right">20000</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\eta_7\)</span></td>
<td align="right">0.34</td>
<td align="right">0.01</td>
<td align="right">0.89</td>
<td align="right">-1.49</td>
<td align="right">-0.24</td>
<td align="right">0.36</td>
<td align="right">0.93</td>
<td align="right">2.04</td>
<td align="right">16262</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\eta_8\)</span></td>
<td align="right">0.05</td>
<td align="right">0.01</td>
<td align="right">0.94</td>
<td align="right">-1.81</td>
<td align="right">-0.57</td>
<td align="right">0.06</td>
<td align="right">0.69</td>
<td align="right">1.91</td>
<td align="right">20000</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta_1\)</span></td>
<td align="right">11.45</td>
<td align="right">0.08</td>
<td align="right">8.27</td>
<td align="right">-1.86</td>
<td align="right">6.07</td>
<td align="right">10.27</td>
<td align="right">15.50</td>
<td align="right">31.68</td>
<td align="right">11788</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta_2\)</span></td>
<td align="right">7.93</td>
<td align="right">0.04</td>
<td align="right">6.15</td>
<td align="right">-4.45</td>
<td align="right">3.99</td>
<td align="right">7.90</td>
<td align="right">11.74</td>
<td align="right">20.44</td>
<td align="right">20000</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta_3\)</span></td>
<td align="right">6.17</td>
<td align="right">0.06</td>
<td align="right">7.67</td>
<td align="right">-11.17</td>
<td align="right">2.07</td>
<td align="right">6.74</td>
<td align="right">10.89</td>
<td align="right">19.94</td>
<td align="right">16041</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta_4\)</span></td>
<td align="right">7.66</td>
<td align="right">0.05</td>
<td align="right">6.51</td>
<td align="right">-5.63</td>
<td align="right">3.75</td>
<td align="right">7.72</td>
<td align="right">11.62</td>
<td align="right">20.78</td>
<td align="right">20000</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta_5\)</span></td>
<td align="right">5.13</td>
<td align="right">0.05</td>
<td align="right">6.41</td>
<td align="right">-9.51</td>
<td align="right">1.37</td>
<td align="right">5.66</td>
<td align="right">9.43</td>
<td align="right">16.41</td>
<td align="right">20000</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta_6\)</span></td>
<td align="right">6.14</td>
<td align="right">0.05</td>
<td align="right">6.66</td>
<td align="right">-8.63</td>
<td align="right">2.35</td>
<td align="right">6.58</td>
<td align="right">10.40</td>
<td align="right">18.47</td>
<td align="right">20000</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\theta_7\)</span></td>
<td align="right">10.64</td>
<td align="right">0.05</td>
<td align="right">6.76</td>
<td align="right">-1.14</td>
<td align="right">6.11</td>
<td align="right">10.11</td>
<td align="right">14.52</td>
<td align="right">25.88</td>
<td align="right">20000</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\theta_8\)</span></td>
<td align="right">8.42</td>
<td align="right">0.06</td>
<td align="right">7.86</td>
<td align="right">-7.24</td>
<td align="right">3.91</td>
<td align="right">8.26</td>
<td align="right">12.60</td>
<td align="right">25.24</td>
<td align="right">16598</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">lp__</td>
<td align="right">-39.55</td>
<td align="right">0.03</td>
<td align="right">2.64</td>
<td align="right">-45.41</td>
<td align="right">-41.15</td>
<td align="right">-39.31</td>
<td align="right">-37.67</td>
<td align="right">-35.12</td>
<td align="right">6325</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>表 <a href="prepare.html#tab:eight-schools-output">2.4</a> 的列为后验量的估计值：依次是均值 <span class="math inline">\(\mathsf{E}(\mu|Y)\)</span>、 标准误(standard error) <span class="math inline">\(\mathsf{Var}(\mu|Y)\)</span>、标准差 (standard deviation) <span class="math inline">\(\mathsf{E}(\sigma|Y)\)</span> 、后验分布的 5 个分位点、有效样本数 <span class="math inline">\(n_{eff}\)</span> 和潜在尺度缩减因子 (potential scale reduction factor)，最后两个量 用来分析采样效率；最后一行表示每次迭代的未正则的对数后验密度 (unnormalized log-posterior density) <span class="math inline">\(\hat{R}\)</span>，当链条都收敛到同一平稳分布的时候，<span class="math inline">\(\hat{R}\)</span> 接近 1。</p>
<p>这里我们对 <span class="math inline">\(\tau\)</span> 采用的非信息先验分布是均匀先验，参数 <span class="math inline">\(\tau\)</span> 的 95% 的置信区间是 (0.22,20.5)， 数据支持 <span class="math inline">\(\tau\)</span> 的范围低于</p>
<div class="figure" style="text-align: center"><span id="fig:posterior-mu-tau"></span>
<img src="figures/posterior_mu_tau.png" alt="对 $\mu,\tau$ 给定均匀先验，后验均值 $\mu$ 和标准差 $\tau$ 的直方图" width="70%" />
<p class="caption">
图 2.3: 对 <span class="math inline">\(\mu,\tau\)</span> 给定均匀先验，后验均值 <span class="math inline">\(\mu\)</span> 和标准差 <span class="math inline">\(\tau\)</span> 的直方图
</p>
</div>
<p>为了得到可靠的后验估计，做出合理的推断，诊断序列的平稳性是必不可少的部分</p>
<div class="figure" style="text-align: center"><span id="fig:diagnostic"></span>
<img src="figures/trace_mu_log_tau.png" alt="诊断图" width="70%" /><img src="figures/mcmc_mean_tau_div.png" alt="诊断图" width="70%" />
<p class="caption">
图 2.4: 诊断图
</p>
</div>
</div>
<div id="section-2.12" class="section level2">
<h2><span class="header-section-number">2.12</span> 方差缩减因子</h2>
<p>为了评估链条之间和内部的混合效果，我们引入潜在尺度缩减因子 <span class="math inline">\(\hat{R}\)</span>，对每个待估的量 <span class="math inline">\(\omega\)</span>，模拟产生 <span class="math inline">\(m\)</span> 条链，每条链有 <span class="math inline">\(n\)</span> 次迭代值 <span class="math inline">\(\omega_{ij} (i = 1,\ldots,n;j=1,\ldots,m)\)</span>，用 <span class="math inline">\(B\)</span> 和 <span class="math inline">\(W\)</span> 分别表示链条之间（不妨看作组间方差）和内部的方差（组内方差）</p>
<p><span class="math display" id="eq:potential-scale-reduction">\[\begin{equation}
\begin{aligned}
&amp; B = \frac{n}{m-1}\sum_{j=1}^{m}(\bar{\omega}_{.j} - \bar{\omega}_{..} ), \quad \bar{\omega}_{.j} = \frac{1}{n}\sum_{i=1}^{n}\omega_{ij}, \quad \bar{\omega}_{..} = \frac{1}{m}\sum_{j=1}^{m} \bar{\omega}_{.j}\\
&amp; W = \frac{1}{m}\sum_{j=1}^{m}s^{2}_{j}, \quad s^{2}_{j} = \frac{1}{n-1}\sum_{i=1}^{n}(\omega_{ij} - \bar{\omega}_{.j})^2
\end{aligned} \tag{2.12}
\end{equation}\]</span></p>
<p><span class="math inline">\(\omega\)</span> 的边际后验方差 <span class="math inline">\(\mathsf{\omega|Y}\)</span> 是 <span class="math inline">\(W\)</span> 和 <span class="math inline">\(B\)</span> 的加权平均</p>
<p><span class="math display">\[\begin{equation}
\widehat{\mathsf{Var}}^{+}(\omega|Y) = \frac{n-1}{n} W + \frac{1}{n} B 
\end{equation}\]</span></p>
<p>当初始分布发散 (overdispersed) 时，这个量会高估边际后验方差，但在链条平稳或 <span class="math inline">\(n \to \infty\)</span> 时，它是无偏的。同时，对任意有限的 <span class="math inline">\(n\)</span>，组内方差 <span class="math inline">\(W\)</span> 应该会低估 <span class="math inline">\(\mathsf{Var}(\omega|Y)\)</span>，因为单个链条没有时间覆盖目标分布；在 <span class="math inline">\(n \to \infty\)</span>， <span class="math inline">\(W\)</span> 的期望会是 <span class="math inline">\(\mathsf{Var}(\omega|Y)\)</span>。</p>
<p>我们通过估计潜在尺度缩减因子 <span class="math inline">\(\hat{R}\)</span> 检测链条的收敛性</p>
<p><span class="math display">\[\begin{equation}
\hat{R} = \sqrt{\frac{\widehat{\mathsf{Var}}^{+}(\omega|Y)}{W}}
\end{equation}\]</span></p>
<p>随着 <span class="math inline">\(n \to \infty\)</span>， <span class="math inline">\(\hat{R}\)</span> 下降到 1。如果 <span class="math inline">\(\hat{R}\)</span> 比较大，我们有理由认为需要增加模拟次数以改进待估参数 <span class="math inline">\(\omega\)</span> 的后验分布 <span class="citation">(Gelman et al. <a href="#ref-Gelman2013R">2013</a>)</span>。</p>

</div>
</div>
<h3>参考文献</h3>
<div id="refs" class="references">
<div id="ref-McCullagh1989">
<p>McCullagh, Peter, and John Nelder. 1989. <em>Generalized Linear Models</em>. Second. London: Chapman; Hall/CRC.</p>
</div>
<div id="ref-wang2004">
<p>王松桂, 史建红, 尹素菊, and 吴密霞. 2004. <em>线性模型引论</em>. 北京: 科学出版社.</p>
</div>
<div id="ref-Bartlett1955">
<p>Bartlett, M. S. 1955. <em>An Introduction to Stochastic Process with Special Reference to Methods and Applications</em>. First. Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-Abramowitz1972">
<p>Abramowitz, Milton, and Irene A. Stegun. 1972. <em>Handbook of Mathematical Functions</em>. Tenth. New York: National Bureau of Standards.</p>
</div>
<div id="ref-Campbell1980">
<p>Campbell, J. B. 1980. “On Temme’s Algorithm for the Modified Bessel Function of the Third Kind.” <em>ACM Transactions on Mathematical Software</em> 6 (4): 581–86.</p>
</div>
<div id="ref-Tierney1986">
<p>Tierney, Luke, and Joseph B. Kadane. 1986. “Accurate Approximations for Posterior Moments and Marginal Densities.” <em>Journal of the American Statistical Association</em> 81 (393): 82–86.</p>
</div>
<div id="ref-Rasmussen2006">
<p>Rasmussen, Carl Edward, and Christopher K. I. Williams. 2006. <em>Gaussian Processes for Machine Learning</em>. Cambridge, Massachusetts: MIT Press.</p>
</div>
<div id="ref-Huang2017COS">
<p>黄湘云. 2017. “随机数生成及其在统计模拟中的应用.” <a href="https://cosx.org/2017/05/random-number-generation" class="uri">https://cosx.org/2017/05/random-number-generation</a>.</p>
</div>
<div id="ref-hoffman2014">
<p>Hoffman, Matthew D., and Andrew Gelman. 2014. “The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.” <em>Journal of Machine Learning Research</em> 15: 1593–1623.</p>
</div>
<div id="ref-Rubin1981">
<p>Rubin, Donald B. 1981. “Estimation in Parallel Randomized Experiments.” <em>Journal of Educational Statistics</em> 6 (4): 377–401.</p>
</div>
<div id="ref-Alderman1980">
<p>Alderman, Donald L., and Donald E. Powers. 1980. “The Effects of Special Preparation on Sat-Verbal Scores.” <em>American Educational Research Journal</em> 17 (2): 239–51.</p>
</div>
<div id="ref-Gelman2003">
<p>Gelman, Andrew, John B. Carlin, Hal S. Stern, and Donald B. Rubin. 2003. <em>Bayesian Data Analysis</em>. Second. London: Chapman; Hall/CRC.</p>
</div>
<div id="ref-Stan2017JSS">
<p>Carpenter, Bob, Andrew Gelman, Matthew Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. 2017. “Stan: A Probabilistic Programming Language.” <em>Journal of Statistical Software</em> 76 (1): 1–32.</p>
</div>
<div id="ref-Gelman2013R">
<p>Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. <em>Bayesian Data Analysis</em>. Third. Boca Raton, Florida: Chapman; Hall/CRC.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>均值参数用 <span class="math inline">\(\mu\)</span> 表示，二项分布里用 <span class="math inline">\(\pi\)</span> 表示；典则参数用 <span class="math inline">\(\theta\)</span> 表示，定义见 <a href="prepare.html#eq:common-exponential-family">(2.1)</a> 式，<span class="math inline">\(\mu\)</span> 和 <span class="math inline">\(\theta\)</span> 的关系在表 <a href="prepare.html#tab:common-characteristics">2.1</a> 的第 6 和第 7 行给出。<a href="prepare.html#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/XiangyunHuang/Thesis-Template-Bookdown/edit/master/01-foundations.Rmd",
"text": "编辑"
},
"download": ["Thesis-Template-Bookdown.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
