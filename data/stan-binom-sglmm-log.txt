samp_sim_binom
Inference for Stan model: fit_sim_binom_gp_exp.
1 chains, each with iter=4000; warmup=2000; thin=1;
post-warmup draws per chain=2000, total post-warmup draws=2000.

           mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat
phi        1.04    0.01 0.49    0.45    0.72    0.92    1.22    2.31  1370    1
sigmasq    0.62    0.01 0.44    0.17    0.32    0.49    0.78    1.74   931    1
alpha      0.06    0.02 0.51   -0.92   -0.27    0.03    0.38    1.14  1045    1
eta[1]    -0.68    0.02 0.83   -2.34   -1.23   -0.67   -0.15    0.98  1199    1
eta[2]    -0.38    0.02 0.95   -2.28   -1.00   -0.38    0.27    1.48  2000    1
eta[3]    -0.40    0.02 0.96   -2.33   -1.01   -0.41    0.27    1.42  2000    1
eta[4]     0.55    0.02 0.90   -1.30   -0.05    0.58    1.19    2.26  2000    1
eta[5]     0.27    0.02 0.92   -1.56   -0.34    0.25    0.90    2.05  2000    1
eta[6]     0.57    0.02 0.92   -1.30   -0.04    0.58    1.19    2.32  2000    1
eta[7]     0.49    0.02 0.92   -1.31   -0.11    0.45    1.09    2.38  1860    1
eta[8]     0.06    0.02 0.96   -1.80   -0.56    0.07    0.69    1.89  2000    1
eta[9]    -0.32    0.02 0.91   -2.18   -0.94   -0.29    0.28    1.43  2000    1
eta[10]   -0.56    0.02 0.99   -2.47   -1.21   -0.55    0.06    1.31  2000    1
eta[11]   -0.54    0.02 0.98   -2.37   -1.22   -0.55    0.13    1.35  2000    1
eta[12]    0.03    0.02 0.97   -1.90   -0.60    0.01    0.68    1.89  2000    1
eta[13]    0.37    0.02 0.96   -1.59   -0.28    0.40    1.02    2.21  2000    1
eta[14]    0.50    0.02 0.96   -1.42   -0.17    0.50    1.14    2.35  2000    1
eta[15]    0.33    0.02 0.93   -1.49   -0.29    0.32    0.98    2.19  2000    1
eta[16]    0.56    0.02 0.91   -1.25   -0.05    0.54    1.19    2.36  2000    1
eta[17]   -0.74    0.02 0.93   -2.52   -1.37   -0.75   -0.11    1.09  1830    1
eta[18]   -0.33    0.02 0.95   -2.17   -0.95   -0.33    0.31    1.59  2000    1
eta[19]   -0.20    0.02 0.95   -2.10   -0.85   -0.23    0.45    1.61  2000    1
eta[20]    0.39    0.02 0.95   -1.36   -0.25    0.39    1.04    2.31  2000    1
eta[21]    0.28    0.02 0.97   -1.59   -0.36    0.27    0.90    2.27  1718    1
eta[22]    0.24    0.02 0.95   -1.58   -0.44    0.23    0.89    2.05  2000    1
eta[23]    0.37    0.02 0.93   -1.47   -0.23    0.36    0.99    2.19  2000    1
eta[24]    0.45    0.02 0.94   -1.31   -0.20    0.46    1.08    2.31  2000    1
eta[25]   -0.69    0.02 0.93   -2.56   -1.30   -0.71   -0.07    1.04  1931    1
eta[26]   -0.14    0.02 0.95   -1.98   -0.78   -0.13    0.50    1.73  2000    1
eta[27]    0.08    0.02 0.97   -1.84   -0.58    0.09    0.74    1.99  1940    1
eta[28]    0.52    0.02 0.94   -1.28   -0.12    0.52    1.18    2.38  2000    1
eta[29]    0.25    0.02 0.98   -1.59   -0.44    0.22    0.90    2.27  2000    1
eta[30]    0.21    0.02 0.98   -1.73   -0.44    0.21    0.87    2.12  1902    1
eta[31]   -0.13    0.02 0.97   -1.96   -0.80   -0.13    0.53    1.78  1744    1
eta[32]    0.61    0.02 0.94   -1.26    0.00    0.63    1.22    2.46  1558    1
eta[33]   -0.34    0.02 0.90   -2.15   -0.92   -0.32    0.26    1.47  1805    1
eta[34]   -0.08    0.02 0.98   -1.92   -0.73   -0.10    0.59    1.80  1950    1
eta[35]    0.08    0.02 0.94   -1.74   -0.55    0.08    0.70    1.98  2000    1
eta[36]    0.23    0.02 0.95   -1.61   -0.40    0.20    0.85    2.14  2000    1
eta[37]    0.43    0.02 0.93   -1.36   -0.21    0.44    1.09    2.23  2000    1
eta[38]    0.01    0.02 0.97   -1.81   -0.64    0.00    0.67    1.90  1840    1
eta[39]   -0.14    0.02 0.96   -2.03   -0.79   -0.15    0.52    1.71  2000    1
eta[40]    0.43    0.02 0.92   -1.37   -0.18    0.42    1.05    2.20  2000    1
eta[41]    0.16    0.02 0.94   -1.67   -0.43    0.13    0.77    2.02  2000    1
eta[42]   -0.12    0.02 0.97   -2.01   -0.75   -0.13    0.51    1.83  1986    1
eta[43]   -0.34    0.02 0.97   -2.20   -1.00   -0.33    0.31    1.60  2000    1
eta[44]    0.15    0.02 1.00   -1.73   -0.52    0.13    0.82    2.10  2000    1
eta[45]    0.56    0.02 0.93   -1.31   -0.09    0.56    1.18    2.39  2000    1
eta[46]    0.11    0.02 0.96   -1.75   -0.54    0.12    0.76    2.00  2000    1
eta[47]   -0.05    0.02 0.95   -1.96   -0.70   -0.04    0.60    1.81  2000    1
eta[48]    0.65    0.02 0.98   -1.35    0.03    0.66    1.32    2.56  1633    1
eta[49]    0.02    0.02 0.90   -1.75   -0.57    0.01    0.64    1.75  2000    1
eta[50]    0.55    0.02 0.96   -1.42   -0.10    0.57    1.23    2.36  2000    1
eta[51]   -0.22    0.02 0.99   -2.12   -0.89   -0.23    0.42    1.72  2000    1
eta[52]   -0.30    0.02 0.97   -2.12   -0.99   -0.33    0.34    1.67  2000    1
eta[53]    0.34    0.02 0.97   -1.62   -0.31    0.33    0.96    2.30  2000    1
eta[54]   -0.13    0.02 0.92   -1.85   -0.74   -0.14    0.49    1.70  2000    1
eta[55]    0.13    0.02 0.95   -1.75   -0.49    0.15    0.76    2.00  2000    1
eta[56]    0.46    0.02 0.95   -1.37   -0.19    0.43    1.11    2.24  2000    1
eta[57]    0.36    0.02 0.95   -1.54   -0.28    0.34    1.01    2.22  2000    1
eta[58]    0.57    0.02 0.97   -1.33   -0.06    0.56    1.28    2.44  2000    1
eta[59]   -0.02    0.02 0.94   -1.82   -0.65   -0.04    0.60    1.82  2000    1
eta[60]   -0.03    0.02 0.98   -1.94   -0.69   -0.01    0.62    1.94  2000    1
eta[61]    0.53    0.02 0.99   -1.39   -0.14    0.54    1.19    2.51  2000    1
eta[62]    0.13    0.02 0.98   -1.78   -0.56    0.14    0.80    2.04  2000    1
eta[63]   -0.09    0.02 0.97   -1.97   -0.75   -0.08    0.57    1.80  2000    1
eta[64]    0.13    0.02 0.93   -1.76   -0.50    0.15    0.76    2.00  2000    1
lp__    -204.44    0.22 6.21 -217.20 -208.34 -204.18 -200.28 -192.99   830    1

Samples were drawn using NUTS(diag_e) at Mon Oct 15 20:20:21 2018.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at
convergence, Rhat=1).
> samp_sim_binom <- sampling(fit_sim_binom_gp, data = sim_binom_data, cores = 1,                               +                            iter = 110000, control = list(adapt_delta = 0.95),
+                            warmup = 10000, thin = 100)

SAMPLING FOR MODEL 'fit_sim_binom_gp_exp' NOW (CHAIN 1).

Gradient evaluation took 0 seconds
1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Adjust your expectations accordingly!


Iteration:      1 / 110000 [  0%]  (Warmup)
Iteration:  10001 / 110000 [  9%]  (Sampling)
Iteration:  21000 / 110000 [ 19%]  (Sampling)
Iteration:  32000 / 110000 [ 29%]  (Sampling)
Iteration:  43000 / 110000 [ 39%]  (Sampling)
Iteration:  54000 / 110000 [ 49%]  (Sampling)
Iteration:  65000 / 110000 [ 59%]  (Sampling)
Iteration:  76000 / 110000 [ 69%]  (Sampling)
Iteration:  87000 / 110000 [ 79%]  (Sampling)
Iteration:  98000 / 110000 [ 89%]  (Sampling)
Iteration: 109000 / 110000 [ 99%]  (Sampling)
Iteration: 110000 / 110000 [100%]  (Sampling)

 Elapsed Time: 125.51 seconds (Warm-up)
               1942.41 seconds (Sampling)
               2067.92 seconds (Total)

> samp_sim_binom
Inference for Stan model: fit_sim_binom_gp_exp.
1 chains, each with iter=110000; warmup=10000; thin=100;
post-warmup draws per chain=1000, total post-warmup draws=1000.

           mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat
phi        1.04    0.02 0.50    0.47    0.71    0.92    1.25    2.32  1000 1.00
sigmasq    0.65    0.02 0.48    0.17    0.34    0.52    0.78    1.96   919 1.00
alpha      0.05    0.02 0.50   -0.95   -0.27    0.05    0.36    1.07   923 1.00
eta[1]    -0.68    0.03 0.85   -2.49   -1.25   -0.64   -0.10    0.87  1000 1.00
eta[2]    -0.37    0.03 0.94   -2.24   -1.00   -0.35    0.23    1.48   928 1.00
eta[3]    -0.36    0.03 0.94   -2.14   -1.02   -0.35    0.25    1.70   956 1.00
eta[4]     0.50    0.03 0.94   -1.41   -0.14    0.53    1.17    2.23   858 1.00
eta[5]     0.28    0.03 0.92   -1.45   -0.34    0.26    0.88    2.09  1000 1.00
eta[6]     0.58    0.03 0.90   -1.20    0.01    0.57    1.19    2.32  1000 1.00
eta[7]     0.52    0.03 0.92   -1.32   -0.10    0.53    1.16    2.30   972 1.00
eta[8]     0.04    0.03 0.93   -1.71   -0.58    0.03    0.62    1.92   778 1.00
eta[9]    -0.25    0.03 0.93   -2.10   -0.90   -0.24    0.37    1.62   902 1.00
eta[10]   -0.58    0.03 0.98   -2.43   -1.26   -0.60    0.10    1.40  1000 1.00
eta[11]   -0.54    0.03 0.95   -2.56   -1.10   -0.52    0.11    1.31  1000 1.00
eta[12]    0.02    0.03 0.94   -1.76   -0.64    0.02    0.63    1.89   953 1.00
eta[13]    0.40    0.03 0.97   -1.53   -0.26    0.38    1.09    2.25  1000 1.00
eta[14]    0.52    0.03 0.96   -1.44   -0.13    0.54    1.15    2.35   983 1.00
eta[15]    0.29    0.03 0.96   -1.62   -0.33    0.26    0.92    2.22  1000 1.00
eta[16]    0.57    0.03 0.95   -1.28   -0.10    0.62    1.21    2.43   984 1.00
eta[17]   -0.74    0.03 0.90   -2.40   -1.32   -0.74   -0.16    1.11  1000 1.00
eta[18]   -0.32    0.03 0.98   -2.19   -1.01   -0.30    0.36    1.65  1000 1.00
eta[19]   -0.21    0.03 0.98   -2.17   -0.85   -0.19    0.43    1.75  1000 1.00
eta[20]    0.38    0.03 0.89   -1.54   -0.16    0.39    0.94    2.14   780 1.00
eta[21]    0.31    0.03 0.95   -1.61   -0.33    0.31    0.96    2.16  1000 1.00
eta[22]    0.17    0.03 0.94   -1.52   -0.48    0.17    0.82    2.04   816 1.00
eta[23]    0.38    0.03 0.91   -1.45   -0.22    0.41    0.99    2.10  1000 1.00
eta[24]    0.46    0.03 0.95   -1.43   -0.14    0.49    1.12    2.30   956 1.00
eta[25]   -0.69    0.03 0.91   -2.49   -1.26   -0.72   -0.04    1.07   896 1.00
eta[26]   -0.13    0.03 0.95   -1.96   -0.79   -0.15    0.53    1.83   971 1.00
eta[27]    0.13    0.03 0.94   -1.60   -0.51    0.10    0.75    2.08   981 1.00
eta[28]    0.50    0.03 0.95   -1.41   -0.11    0.52    1.14    2.36  1000 1.00
eta[29]    0.21    0.03 0.97   -1.73   -0.41    0.21    0.86    2.09   998 1.00
eta[30]    0.18    0.03 0.95   -1.64   -0.45    0.16    0.78    2.11  1000 1.00
eta[31]   -0.15    0.03 0.98   -2.07   -0.84   -0.17    0.54    1.78   974 1.00
eta[32]    0.61    0.03 0.97   -1.31   -0.07    0.64    1.28    2.38   994 1.00
eta[33]   -0.40    0.03 0.94   -2.29   -1.03   -0.41    0.24    1.41  1000 1.00
eta[34]   -0.14    0.03 0.96   -2.03   -0.77   -0.12    0.55    1.68  1000 1.00
eta[35]    0.02    0.03 0.94   -1.80   -0.59    0.02    0.66    1.76   861 1.00
eta[36]    0.27    0.03 0.93   -1.61   -0.35    0.31    0.91    2.07   731 1.00
eta[37]    0.41    0.03 0.97   -1.41   -0.26    0.43    1.06    2.27   981 1.00
eta[38]   -0.05    0.03 0.98   -1.91   -0.73   -0.05    0.60    1.95   909 1.00
eta[39]   -0.09    0.03 0.96   -2.12   -0.72   -0.09    0.55    1.76  1000 1.00
eta[40]    0.44    0.03 0.93   -1.38   -0.15    0.45    1.06    2.21  1000 1.00
eta[41]    0.16    0.03 0.91   -1.56   -0.45    0.16    0.74    2.01   718 1.00
eta[42]   -0.13    0.03 0.99   -2.00   -0.77   -0.10    0.50    1.83   973 1.00
eta[43]   -0.37    0.03 0.95   -2.26   -1.02   -0.40    0.29    1.60  1000 1.00
eta[44]    0.19    0.03 0.97   -1.77   -0.43    0.21    0.81    2.15   935 1.00
eta[45]    0.55    0.03 0.96   -1.36   -0.09    0.54    1.20    2.35   996 1.00
eta[46]    0.16    0.03 0.93   -1.70   -0.45    0.15    0.76    1.97   876 1.00
eta[47]   -0.06    0.03 0.92   -1.89   -0.70   -0.06    0.54    1.81  1000 1.00
eta[48]    0.68    0.03 0.95   -1.26    0.03    0.66    1.31    2.58  1000 1.00
eta[49]    0.01    0.03 0.94   -1.87   -0.59    0.04    0.66    1.76  1000 1.00
eta[50]    0.58    0.03 0.97   -1.43   -0.05    0.62    1.23    2.44  1000 1.00
eta[51]   -0.19    0.03 0.98   -2.12   -0.89   -0.21    0.43    1.80   905 1.00
eta[52]   -0.31    0.03 0.99   -2.26   -1.00   -0.32    0.39    1.63   968 1.00
eta[53]    0.37    0.03 0.95   -1.51   -0.27    0.37    1.01    2.19  1000 1.00
eta[54]   -0.18    0.03 0.96   -2.06   -0.81   -0.19    0.50    1.62   877 1.00
eta[55]    0.07    0.03 0.94   -1.78   -0.58    0.08    0.72    1.82   999 1.00
eta[56]    0.47    0.03 0.94   -1.35   -0.18    0.50    1.09    2.24  1000 1.00
eta[57]    0.35    0.03 0.94   -1.55   -0.26    0.37    1.00    2.12   920 1.00
eta[58]    0.59    0.03 0.99   -1.33   -0.06    0.62    1.27    2.52   932 1.00
eta[59]   -0.01    0.03 0.96   -1.83   -0.69    0.01    0.63    1.89   797 1.00
eta[60]   -0.03    0.03 0.98   -2.00   -0.64   -0.02    0.65    1.85   870 1.00
eta[61]    0.52    0.03 0.98   -1.51   -0.10    0.53    1.15    2.35  1000 1.00
eta[62]    0.10    0.03 0.97   -1.75   -0.53    0.08    0.77    1.94   918 1.00
eta[63]   -0.12    0.03 0.98   -2.11   -0.78   -0.12    0.52    1.75  1000 1.00
eta[64]    0.13    0.03 0.96   -1.87   -0.49    0.13    0.78    2.04   940 1.00
lp__    -204.28    0.20 6.32 -217.31 -208.26 -204.20 -200.11 -192.34  1000 1.01

Samples were drawn using NUTS(diag_e) at Mon Oct 15 20:56:49 2018.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at
convergence, Rhat=1).
